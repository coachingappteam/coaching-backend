{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow_core.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.client import device_lib\n",
    "tf.debugging.set_log_device_placement(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('Label')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector_input = pd.read_csv(\"vector_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5399285525639064\t2.565650878791291\t-0.025722326227384684\tBack\n",
      "2.5513059615790974\t2.5653436116122683\t-0.014037650033170923\tBreast\n",
      "2.5353059289419377\t2.5700508755082443\t-0.034744946566306556\tButterfly\n",
      "2.5367386759581882\t2.569610663499831\t-0.03287198754164278\tDrill\n",
      "2.5362393711341644\t2.5713787300414563\t-0.03513935890729192\tFree\n",
      "2.5518178479618068\t2.569058757174613\t-0.017240909212806077\tIm\n",
      "2.5407934496539624\t2.5683349226368084\t-0.027541472982846038\tKick\n",
      "2.5381146511043475\t2.566596346059315\t-0.02848169495496755\tPullPaddle\n"
     ]
    }
   ],
   "source": [
    "styles = ['Back', 'Breast','Butterfly','Drill',\n",
    "          'Free','Im', 'Kick','PullPaddle']\n",
    "\n",
    "with_role = train_vector_input[train_vector_input.Role ==1]\n",
    "for style in styles:    \n",
    "    with_style = with_role[with_role[style+\"Reps\"] > 0]\n",
    "    m0 = with_style[with_style.Label == 0][style+\"Reps\"].mean()\n",
    "    m1 = with_style[with_style.Label == 1][style+\"Reps\"].mean()\n",
    "    print(m0, m1, m0-m1, style, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = feature_column.numeric_column(\"Role\")\n",
    "\n",
    "\n",
    "competition_week = feature_column.numeric_column(\"CompetitionWeek\")\n",
    "\n",
    "\n",
    "back_reps = feature_column.numeric_column(\"BackReps\")\n",
    "\n",
    "\n",
    "back_distance = feature_column.numeric_column(\"BackDistance\")\n",
    "\n",
    "\n",
    "back_split = feature_column.numeric_column(\"BackAverageSplit\")\n",
    "\n",
    "\n",
    "breast_reps = feature_column.numeric_column(\"BreastReps\")\n",
    "\n",
    "\n",
    "breast_distance = feature_column.numeric_column(\"BreastDistance\")\n",
    "\n",
    "\n",
    "breast_split = feature_column.numeric_column(\"BreastAverageSplit\")\n",
    "\n",
    "\n",
    "butterfly_reps = feature_column.numeric_column(\"ButterflyReps\")\n",
    "\n",
    "\n",
    "butterfly_distance = feature_column.numeric_column(\"ButterflyDistance\")\n",
    "\n",
    "\n",
    "butterfly_split = feature_column.numeric_column(\"ButterflyAverageSplit\")\n",
    "\n",
    "\n",
    "drill_reps = feature_column.numeric_column(\"DrillReps\")\n",
    "\n",
    "\n",
    "drill_distance = feature_column.numeric_column(\"DrillDistance\")\n",
    "\n",
    "\n",
    "drill_split = feature_column.numeric_column(\"DrillAverageSplit\")\n",
    "\n",
    "\n",
    "free_reps = feature_column.numeric_column(\"FreeReps\")\n",
    "\n",
    "\n",
    "free_distance = feature_column.numeric_column(\"FreeDistance\")\n",
    "\n",
    "\n",
    "free_split = feature_column.numeric_column(\"FreeAverageSplit\")\n",
    "\n",
    "\n",
    "im_reps = feature_column.numeric_column(\"ImReps\")\n",
    "\n",
    "\n",
    "im_distance = feature_column.numeric_column(\"ImDistance\")\n",
    "\n",
    "\n",
    "im_split = feature_column.numeric_column(\"ImAverageSplit\")\n",
    "\n",
    "\n",
    "kick_reps = feature_column.numeric_column(\"KickReps\")\n",
    "\n",
    "\n",
    "kick_distance = feature_column.numeric_column(\"KickDistance\")\n",
    "\n",
    "\n",
    "kick_split = feature_column.numeric_column(\"KickAverageSplit\")\n",
    "\n",
    "\n",
    "pull_reps = feature_column.numeric_column(\"PullPaddleReps\")\n",
    "\n",
    "\n",
    "pull_distance = feature_column.numeric_column(\"PullPaddleDistance\")\n",
    "\n",
    "\n",
    "pull_split = feature_column.numeric_column(\"PullPaddleAverageSplit\")\n",
    "\n",
    "\n",
    "total_distance = feature_column.numeric_column(\"TotalDistance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2603248 train examples\n",
      "650812 validation examples\n",
      "813516 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(train_vector_input, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousRandomSeedGenerator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [role, competition_week, back_reps, back_distance,\n",
    "                back_split, breast_reps, breast_distance, \n",
    "                breast_split, butterfly_reps, butterfly_distance,\n",
    "                butterfly_split, drill_reps, drill_distance,\n",
    "                drill_split, free_reps, free_distance,\n",
    "                free_split, im_reps, im_distance, \n",
    "                im_split, kick_reps, kick_distance,\n",
    "                kick_split, pull_reps, pull_distance,\n",
    "                pull_split, total_distance\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(train_vector_input, test_size=0.1, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Role                        int64\n",
       "CompetitionWeek             int64\n",
       "BackReps                    int64\n",
       "BackDistance                int64\n",
       "BackAverageSplit          float64\n",
       "BreastReps                  int64\n",
       "BreastDistance              int64\n",
       "BreastAverageSplit        float64\n",
       "ButterflyReps               int64\n",
       "ButterflyDistance           int64\n",
       "ButterflyAverageSplit     float64\n",
       "DrillReps                   int64\n",
       "DrillDistance               int64\n",
       "DrillAverageSplit         float64\n",
       "FreeReps                    int64\n",
       "FreeDistance                int64\n",
       "FreeAverageSplit          float64\n",
       "ImReps                      int64\n",
       "ImDistance                  int64\n",
       "ImAverageSplit            float64\n",
       "KickReps                    int64\n",
       "KickDistance                int64\n",
       "KickAverageSplit          float64\n",
       "PullPaddleReps              int64\n",
       "PullPaddleDistance          int64\n",
       "PullPaddleAverageSplit    float64\n",
       "TotalDistance               int64\n",
       "Label                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['Role', 'CompetitionWeek', 'BackReps', 'BackDistance',\n",
    "       'BackAverageSplit', 'BreastReps', 'BreastDistance',\n",
    "       'BreastAverageSplit', 'ButterflyReps', 'ButterflyDistance',\n",
    "       'ButterflyAverageSplit', 'DrillReps', 'DrillDistance',\n",
    "       'DrillAverageSplit', 'FreeReps', 'FreeDistance', 'FreeAverageSplit',\n",
    "       'ImReps', 'ImDistance', 'ImAverageSplit', 'KickReps', 'KickDistance',\n",
    "       'KickAverageSplit', 'PullPaddleReps', 'PullPaddleDistance',\n",
    "       'PullPaddleAverageSplit', 'TotalDistance']\n",
    "LABEL= 'Label'\n",
    "\n",
    "def get_input_fn(data_set, num_epochs=None, n_batch = 128, shuffle=True):\n",
    "    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "       x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),\n",
    "       y = pd.Series(data_set[LABEL].values),\n",
    "       batch_size=n_batch,   \n",
    "       num_epochs=num_epochs,\n",
    "       shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TensorFlow Estimator Linear Classifier Creation, training, and evaluation'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ongoing/train4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002B165FD6188>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From c:\\users\\luisr\\miniconda3\\envs\\coaching-env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\users\\luisr\\miniconda3\\envs\\coaching-env\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From c:\\users\\luisr\\miniconda3\\envs\\coaching-env\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From c:\\users\\luisr\\miniconda3\\envs\\coaching-env\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\luisr\\miniconda3\\envs\\coaching-env\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From c:\\users\\luisr\\miniconda3\\envs\\coaching-env\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From c:\\users\\luisr\\miniconda3\\envs\\coaching-env\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From c:\\users\\luisr\\miniconda3\\envs\\coaching-env\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ongoing/train4\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 66.4023\n",
      "INFO:tensorflow:loss = 1.8294587, step = 100 (1.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.022\n",
      "INFO:tensorflow:loss = 4.587011, step = 200 (0.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.282\n",
      "INFO:tensorflow:loss = 3.3973584, step = 300 (0.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.105\n",
      "INFO:tensorflow:loss = 0.52593404, step = 400 (0.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.038\n",
      "INFO:tensorflow:loss = 1.4322059, step = 500 (0.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.05\n",
      "INFO:tensorflow:loss = 1.0812118, step = 600 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.178\n",
      "INFO:tensorflow:loss = 0.72264177, step = 700 (0.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.869\n",
      "INFO:tensorflow:loss = 0.7812904, step = 800 (0.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.165\n",
      "INFO:tensorflow:loss = 1.6913347, step = 900 (0.732 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ongoing/train4\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5953139.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x2b165fd0dc8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-16T17:18:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ongoing/train4\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Evaluation [200/1000]\n",
      "INFO:tensorflow:Evaluation [300/1000]\n",
      "INFO:tensorflow:Evaluation [400/1000]\n",
      "INFO:tensorflow:Evaluation [500/1000]\n",
      "INFO:tensorflow:Evaluation [600/1000]\n",
      "INFO:tensorflow:Evaluation [700/1000]\n",
      "INFO:tensorflow:Evaluation [800/1000]\n",
      "INFO:tensorflow:Evaluation [900/1000]\n",
      "INFO:tensorflow:Evaluation [1000/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-16-17:18:51\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8973594, accuracy_baseline = 0.88653123, auc = 0.759607, auc_precision_recall = 0.9444892, average_loss = 0.5498106, global_step = 1000, label/mean = 0.88653123, loss = 0.5498106, precision = 0.917887, prediction/mean = 0.9326404, recall = 0.9710952\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ongoing/train4\\model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8973594,\n",
       " 'accuracy_baseline': 0.88653123,\n",
       " 'auc': 0.759607,\n",
       " 'auc_precision_recall': 0.9444892,\n",
       " 'average_loss': 0.5498106,\n",
       " 'label/mean': 0.88653123,\n",
       " 'loss': 0.5498106,\n",
       " 'precision': 0.917887,\n",
       " 'prediction/mean': 0.9326404,\n",
       " 'recall': 0.9710952,\n",
       " 'global_step': 1000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TensorFlow Estimator Linear Classifier Creation, training, and evaluation'''\n",
    "\n",
    "model = tf.estimator.LinearClassifier(feature_columns=feature_columns,model_dir=\"ongoing/train4\", n_classes=2)\n",
    "\n",
    "model.train(get_input_fn(X_train, num_epochs=None, n_batch = 128, shuffle=False), steps=1000)\n",
    "    \n",
    "model.evaluate(get_input_fn(X_test, num_epochs=1, n_batch = 128, shuffle=False), steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "'''Keras Sequential Model Creation and Training'''\n",
    "with tf.device('/GPU:0'):\n",
    "    model = tf.keras.Sequential([\n",
    "      feature_layer,\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_ds,\n",
    "              validation_data=val_ds,\n",
    "              epochs=5)\n",
    "    \n",
    "'''Check Keras Model Accuracy'''\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function to save Keras Model'''\n",
    "model.save('keras\\my_model')\n",
    "\n",
    "'''Function to load Keras Model'''\n",
    "# model = tf.keras.models.load_model('keras\\my_model')\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
